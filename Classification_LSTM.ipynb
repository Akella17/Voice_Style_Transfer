{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Classification_LSTM.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"Q6EAR2E7C96s","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":190},"outputId":"5ccfabcb-05b0-4755-ffcd-0fcecc9b987e","executionInfo":{"status":"ok","timestamp":1523389312375,"user_tz":-330,"elapsed":20157,"user":{"displayName":"Ruthvik Reddy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"113131962877865104150"}}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-driv/e-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["gpg: keybox '/tmp/tmpczf5qk8g/pubring.gpg' created\n","gpg: /tmp/tmpczf5qk8g/trustdb.gpg: trustdb created\n","gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n","gpg: Total number processed: 1\n","gpg:               imported: 1\n","Warning: apt-key output should not be parsed (stdout is not a terminal)\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"metadata":{"id":"2NL-DCe5DILx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive\n","import os\n","os.chdir('/content/drive')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SGx13TbtDk0L","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["os.chdir('drive')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0XBC4yGCFarf","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["os.chdir('Speaker Classification')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7lCuiIGmDrJ3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":258},"outputId":"2a90150a-3d9f-42aa-a527-ef0886d2a2cb","executionInfo":{"status":"ok","timestamp":1523389444334,"user_tz":-330,"elapsed":6894,"user":{"displayName":"Ruthvik Reddy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"113131962877865104150"}}},"cell_type":"code","source":["!pip install librosa\n","!pip install scipy"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages\r\n","Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa)\r\n","Requirement already satisfied: joblib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from librosa)\r\n","Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa)\n","Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa)\n","Requirement already satisfied: numba>=0.32 in /usr/local/lib/python3.6/dist-packages (from resampy>=0.2.0->librosa)\n","Requirement already satisfied: llvmlite>=0.22.0.dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.32->resampy>=0.2.0->librosa)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages\n","Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy)\n"],"name":"stdout"}]},{"metadata":{"id":"b40sloN7EDku","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":765},"outputId":"5996b0ef-0f75-4a1f-b1a0-0785ebabe89c","executionInfo":{"status":"ok","timestamp":1523389680069,"user_tz":-330,"elapsed":223839,"user":{"displayName":"Ruthvik Reddy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"113131962877865104150"}}},"cell_type":"code","source":["import scipy.io.wavfile as wav\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import scipy.stats as stats\n","from skimage.util.shape import view_as_windows\n","from sklearn.model_selection import train_test_split\n","from sklearn import preprocessing\n","from sklearn.utils import shuffle\n","import tensorflow as tf\n","import librosa\n","import librosa.display\n","from scipy import misc\n","import pandas as pd\n","from matplotlib.pyplot import specgram\n","import math\n","import matplotlib.image as mpimg\n","\n","#load the .wav data\n","print(\"Loading the data from .wav files...\")\n","print(\"\")\n","voice_00 = librosa.load('data/voice_01.wav', sr = 16000)\n","voice_01 = librosa.load('data/voice_02.wav', sr = 16000)\n","voice_02 = librosa.load('data/voice_03.wav', sr = 16000)\n","voice_03 = librosa.load('data/voice_04.wav', sr = 16000)\n","voice_04 = librosa.load('data/voice_05.wav', sr = 16000)\n","voice_05 = librosa.load('data/voice_06.wav', sr = 16000)\n","voice_06 = librosa.load('data/voice_07.wav', sr = 16000)\n","voice_07 = librosa.load('data/voice_08.wav', sr = 16000)\n","voice_08 = librosa.load('data/voice_09.wav', sr = 16000)\n","voice_09 = librosa.load('data/voice_10.wav', sr = 16000)\n","print(\"Loaded\")\n","print(\"\")\n","\n","#inspect the data\n","voices = [voice_00, voice_01, voice_02, voice_03, voice_04, voice_05, voice_06, voice_07, voice_08, voice_09]\n","for voice_file in voices:\n","    print('Sample Rate:', voice_file[1], '|', 'Shape of Array:', voice_file[0].shape) #2 channel audio\n","\n","#only use the audio data (librosa load function also outputs sample rate)\n","all_voice_files = []\n","for voice in voices:\n","    all_voice_files.append(voice[0])\n","    \n","#look at the attributes of each file\n","#min, max, mean, standard deviation\n","indexer = 0\n","for voice in all_voice_files:\n","    print(\"Sample\", indexer, \"|\", \"Mean:\", np.mean(voice), \"|\", \"Max:\", np.max(voice), \"|\", \\\n","          \"Min:\", np.min(voice), \"|\", \"Std Dev:\", np.std(voice))\n","    indexer += 1\n","    \n","\"\"\"\n","Find all 200ms samples that have clear audio data in them\n","\"\"\"\n","#in each sample, find 200ms chunks that have a mean over the total average + standard deviation\n","window_shape = 16000 / 5\n","\n","voice_data = []\n","voice_labels = []\n","voice_number = 0\n","\n","for voice in all_voice_files:\n","    positive_full_array = view_as_windows(np.absolute(voice), window_shape)\n","    positive_full_array = positive_full_array[::int(window_shape / 2)] #keep every nth row, where n is window_shape/2 (For some overlap)\n","    temp_full_array = view_as_windows(voice, window_shape)\n","    temp_full_array = temp_full_array[::int(window_shape / 2)]\n","    \n","    for window_index in range(len(temp_full_array)):\n","        if np.mean(positive_full_array[window_index]) > (np.mean(voice) + np.std(voice)):\n","            voice_data.append(temp_full_array[window_index])\n","            voice_labels.append(voice_number)\n","            \n","    voice_number += 1\n","    \n","voice_data = np.array(voice_data)\n","print(\"Number of samples:\", voice_data.shape)\n","#normalize the data\n","#voice_data_normalized = preprocessing.normalize(voice_data)\n","\n","voice_labels = np.array(voice_labels)\n","#one-hot encode the labels\n","voice_labels = np.eye(10)[voice_labels]\n","\n","print(\"Number of labels:\", voice_labels.shape)\n","\n","#determine how many of each speaker is in the samples/labels dataset\n","identity_matrix = np.identity(10)\n","number_of_samples = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","for i in range(len(voice_labels)):\n","    for j in range(10):\n","        number_of_samples[j] += np.sum(np.all(np.equal(voice_labels[i], identity_matrix[j])))\n","\n","for i in range(10):\n","    print(\"Number of samples from voice\", i, ':', number_of_samples[i])\n","\n","\"\"\"\n","split the data into sets\n","\"\"\"\n","\n","#split into training and testing sets - 60% train, 20% validation, 20% test\n","X_train, X_test, y_train, y_test = train_test_split(voice_data, voice_labels, test_size = 0.40, random_state = 7)\n","X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.5, random_state = 7)\n","print(\"Training Set:\", X_train.shape, y_train.shape)\n","print(\"Testing Set:\", X_test.shape, y_test.shape)\n","print(\"Validation Set:\", X_val.shape, y_val.shape)\n","\n","print(\"Created raw audio data and labels from .wav files.\")\n","print(\"Shape: \", X_train[0].shape)\n","\n","def generate_mfcc():\n","    train_out = []\n","    val_out = []\n","    test_out = []\n","\n","    for i in range(len(X_train)):\n","        temp_train = np.transpose(np.expand_dims(librosa.feature.mfcc(y=X_train[i], sr=16000), axis=0), [0, 2, 1])\n","        train_out.append(temp_train)\n","    train_out = np.array(train_out)\n","\n","    for i in range(len(X_test)):\n","        temp_test = np.transpose(np.expand_dims(librosa.feature.mfcc(y=X_test[i], sr=16000), axis=0), [0, 2, 1])\n","        test_out.append(temp_test)\n","    test_out = np.array(test_out)\n","\n","    for i in range(len(X_val)):\n","        temp_val = np.transpose(np.expand_dims(librosa.feature.mfcc(y=X_val[i], sr=16000), axis=0), [0, 2, 1])\n","        val_out.append(temp_val)\n","    val_out = np.array(val_out)\n","\n","    print(train_out.shape)\n","    print(val_out.shape)\n","    print(test_out.shape)\n","    return train_out, val_out, test_out\n","        \n","        \n","X_train_out, X_val_out, X_test_out = generate_mfcc()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loading the data from .wav files...\n","\n","Loaded\n","\n","Sample Rate: 16000 | Shape of Array: (2880000,)\n","Sample Rate: 16000 | Shape of Array: (2880000,)\n","Sample Rate: 16000 | Shape of Array: (2880000,)\n","Sample Rate: 16000 | Shape of Array: (2880000,)\n","Sample Rate: 16000 | Shape of Array: (2880000,)\n","Sample Rate: 16000 | Shape of Array: (2880000,)\n","Sample Rate: 16000 | Shape of Array: (2880000,)\n","Sample Rate: 16000 | Shape of Array: (2880000,)\n","Sample Rate: 16000 | Shape of Array: (2880000,)\n","Sample Rate: 16000 | Shape of Array: (2880000,)\n","Sample 0 | Mean: 4.7888716e-06 | Max: 0.91083825 | Min: -0.5682895 | Std Dev: 0.054258995\n","Sample 1 | Mean: -0.0002666064 | Max: 0.64925575 | Min: -0.8183496 | Std Dev: 0.07194531\n","Sample 2 | Mean: -2.390854e-06 | Max: 0.4160391 | Min: -0.39128813 | Std Dev: 0.054623123\n","Sample 3 | Mean: 3.47779e-06 | Max: 0.40846926 | Min: -0.43750376 | Std Dev: 0.043937676\n","Sample 4 | Mean: -1.792521e-06 | Max: 0.3158226 | Min: -0.27962488 | Std Dev: 0.03735458\n","Sample 5 | Mean: -1.8312595e-06 | Max: 0.49208727 | Min: -0.46745995 | Std Dev: 0.045943175\n","Sample 6 | Mean: -3.3488047e-07 | Max: 0.4111276 | Min: -0.40648526 | Std Dev: 0.04125816\n","Sample 7 | Mean: -9.780429e-06 | Max: 0.5170332 | Min: -0.55148816 | Std Dev: 0.046136845\n","Sample 8 | Mean: -1.0130902e-05 | Max: 0.23891516 | Min: -0.23076381 | Std Dev: 0.03328587\n","Sample 9 | Mean: -5.169409e-06 | Max: 0.86699617 | Min: -0.8164575 | Std Dev: 0.049799424\n","Number of samples: (2694, 3200)\n","Number of labels: (2694, 10)\n","Number of samples from voice 0 : 249\n","Number of samples from voice 1 : 281\n","Number of samples from voice 2 : 265\n","Number of samples from voice 3 : 250\n","Number of samples from voice 4 : 305\n","Number of samples from voice 5 : 233\n","Number of samples from voice 6 : 347\n","Number of samples from voice 7 : 259\n","Number of samples from voice 8 : 292\n","Number of samples from voice 9 : 213\n","Training Set: (1616, 3200) (1616, 10)\n","Testing Set: (539, 3200) (539, 10)\n","Validation Set: (539, 3200) (539, 10)\n","Created raw audio data and labels from .wav files.\n","Shape:  (3200,)\n","(1616, 1, 7, 20)\n","(539, 1, 7, 20)\n","(539, 1, 7, 20)\n"],"name":"stdout"}]},{"metadata":{"id":"879R7nQkGqVV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"68938b02-29b3-4dd2-adf7-f44b9e73f231","executionInfo":{"status":"ok","timestamp":1523389813537,"user_tz":-330,"elapsed":1050,"user":{"displayName":"Ruthvik Reddy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"113131962877865104150"}}},"cell_type":"code","source":["X_train_out = np.squeeze(X_train_out, axis=1)\n","X_val_out = np.squeeze(X_val_out, axis=1)\n","X_test_out = np.squeeze(X_test_out, axis=1)\n","\n","print(X_train_out.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(1616, 7, 20)\n"],"name":"stdout"}]},{"metadata":{"id":"JRQhI8syEh95","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["epochs = 100\n","timesteps = 7\n","hidden_units = 512\n","batch_size = 10"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bGsAOXQQHEou","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":221},"outputId":"f4e69d7a-5f21-4fe4-d1e5-c4cfdd24496e","executionInfo":{"status":"ok","timestamp":1523390836935,"user_tz":-330,"elapsed":1911,"user":{"displayName":"Ruthvik Reddy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"113131962877865104150"}}},"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","from keras.layers import LSTM\n","\n","model = Sequential()\n","model.add(LSTM(hidden_units, input_shape=(timesteps, 20), dropout=0.25, recurrent_dropout=0.45))\n","model.add(Dense(10, activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model.summary())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_3 (LSTM)                (None, 512)               1091584   \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 10)                5130      \n","=================================================================\n","Total params: 1,096,714\n","Trainable params: 1,096,714\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"metadata":{"id":"3s3PK6gMH4Gv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":3434},"outputId":"c2c4003b-d92b-4969-f5f9-1a220dc5705c","executionInfo":{"status":"ok","timestamp":1523391245331,"user_tz":-330,"elapsed":402348,"user":{"displayName":"Ruthvik Reddy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"113131962877865104150"}}},"cell_type":"code","source":["model.fit(X_train_out, y_train, epochs=epochs, batch_size= batch_size, verbose=2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n"," - 5s - loss: 1.7600 - acc: 0.3923\n","Epoch 2/100\n"," - 4s - loss: 1.1455 - acc: 0.6176\n","Epoch 3/100\n"," - 4s - loss: 0.8980 - acc: 0.7116\n","Epoch 4/100\n"," - 4s - loss: 0.7551 - acc: 0.7420\n","Epoch 5/100\n"," - 4s - loss: 0.6908 - acc: 0.7649\n","Epoch 6/100\n"," - 4s - loss: 0.6464 - acc: 0.7729\n","Epoch 7/100\n"," - 4s - loss: 0.6173 - acc: 0.7877\n","Epoch 8/100\n"," - 4s - loss: 0.5976 - acc: 0.7946\n","Epoch 9/100\n"," - 4s - loss: 0.5931 - acc: 0.8001\n","Epoch 10/100\n"," - 4s - loss: 0.5507 - acc: 0.8261\n","Epoch 11/100\n"," - 4s - loss: 0.5189 - acc: 0.8224\n","Epoch 12/100\n"," - 4s - loss: 0.5028 - acc: 0.8168\n","Epoch 13/100\n"," - 4s - loss: 0.4921 - acc: 0.8373\n","Epoch 14/100\n"," - 4s - loss: 0.4809 - acc: 0.8366\n","Epoch 15/100\n"," - 4s - loss: 0.4888 - acc: 0.8274\n","Epoch 16/100\n"," - 4s - loss: 0.4675 - acc: 0.8453\n","Epoch 17/100\n"," - 4s - loss: 0.4862 - acc: 0.8366\n","Epoch 18/100\n"," - 4s - loss: 0.4645 - acc: 0.8416\n","Epoch 19/100\n"," - 4s - loss: 0.4210 - acc: 0.8540\n","Epoch 20/100\n"," - 4s - loss: 0.4218 - acc: 0.8564\n","Epoch 21/100\n"," - 4s - loss: 0.4241 - acc: 0.8583\n","Epoch 22/100\n"," - 4s - loss: 0.4064 - acc: 0.8738\n","Epoch 23/100\n"," - 4s - loss: 0.4189 - acc: 0.8601\n","Epoch 24/100\n"," - 4s - loss: 0.3992 - acc: 0.8651\n","Epoch 25/100\n"," - 4s - loss: 0.4217 - acc: 0.8564\n","Epoch 26/100\n"," - 4s - loss: 0.4044 - acc: 0.8639\n","Epoch 27/100\n"," - 4s - loss: 0.3941 - acc: 0.8651\n","Epoch 28/100\n"," - 4s - loss: 0.3921 - acc: 0.8657\n","Epoch 29/100\n"," - 4s - loss: 0.3923 - acc: 0.8558\n","Epoch 30/100\n"," - 4s - loss: 0.3746 - acc: 0.8769\n","Epoch 31/100\n"," - 4s - loss: 0.3924 - acc: 0.8558\n","Epoch 32/100\n"," - 4s - loss: 0.3684 - acc: 0.8719\n","Epoch 33/100\n"," - 4s - loss: 0.3681 - acc: 0.8750\n","Epoch 34/100\n"," - 4s - loss: 0.3684 - acc: 0.8713\n","Epoch 35/100\n"," - 4s - loss: 0.3539 - acc: 0.8750\n","Epoch 36/100\n"," - 4s - loss: 0.3708 - acc: 0.8818\n","Epoch 37/100\n"," - 4s - loss: 0.3484 - acc: 0.8824\n","Epoch 38/100\n"," - 4s - loss: 0.3815 - acc: 0.8719\n","Epoch 39/100\n"," - 4s - loss: 0.3868 - acc: 0.8620\n","Epoch 40/100\n"," - 4s - loss: 0.3391 - acc: 0.8830\n","Epoch 41/100\n"," - 4s - loss: 0.3594 - acc: 0.8781\n","Epoch 42/100\n"," - 4s - loss: 0.3200 - acc: 0.8874\n","Epoch 43/100\n"," - 4s - loss: 0.3266 - acc: 0.8849\n","Epoch 44/100\n"," - 4s - loss: 0.3230 - acc: 0.8855\n","Epoch 45/100\n"," - 4s - loss: 0.3360 - acc: 0.8824\n","Epoch 46/100\n"],"name":"stdout"},{"output_type":"stream","text":[" - 4s - loss: 0.3383 - acc: 0.8756\n","Epoch 47/100\n"," - 4s - loss: 0.3317 - acc: 0.8830\n","Epoch 48/100\n"," - 4s - loss: 0.3079 - acc: 0.8929\n","Epoch 49/100\n"," - 4s - loss: 0.3598 - acc: 0.8787\n","Epoch 50/100\n"," - 4s - loss: 0.3116 - acc: 0.8960\n","Epoch 51/100\n"," - 4s - loss: 0.3179 - acc: 0.8892\n","Epoch 52/100\n"," - 4s - loss: 0.3302 - acc: 0.8843\n","Epoch 53/100\n"," - 4s - loss: 0.3412 - acc: 0.8824\n","Epoch 54/100\n"," - 4s - loss: 0.3212 - acc: 0.8837\n","Epoch 55/100\n"," - 4s - loss: 0.3207 - acc: 0.8905\n","Epoch 56/100\n"," - 4s - loss: 0.3053 - acc: 0.8892\n","Epoch 57/100\n"," - 4s - loss: 0.3249 - acc: 0.8917\n","Epoch 58/100\n"," - 4s - loss: 0.3115 - acc: 0.8849\n","Epoch 59/100\n"," - 4s - loss: 0.2990 - acc: 0.8979\n","Epoch 60/100\n"," - 4s - loss: 0.3181 - acc: 0.8899\n","Epoch 61/100\n"," - 4s - loss: 0.2905 - acc: 0.9004\n","Epoch 62/100\n"," - 4s - loss: 0.3311 - acc: 0.8787\n","Epoch 63/100\n"," - 4s - loss: 0.3064 - acc: 0.8979\n","Epoch 64/100\n"," - 4s - loss: 0.3143 - acc: 0.8886\n","Epoch 65/100\n"," - 4s - loss: 0.2917 - acc: 0.8923\n","Epoch 66/100\n"," - 4s - loss: 0.3005 - acc: 0.8917\n","Epoch 67/100\n"," - 4s - loss: 0.3056 - acc: 0.8892\n","Epoch 68/100\n"," - 4s - loss: 0.3117 - acc: 0.8812\n","Epoch 69/100\n"," - 4s - loss: 0.2974 - acc: 0.9047\n","Epoch 70/100\n"," - 4s - loss: 0.2994 - acc: 0.8960\n","Epoch 71/100\n"," - 4s - loss: 0.2944 - acc: 0.9059\n","Epoch 72/100\n"," - 4s - loss: 0.3036 - acc: 0.8954\n","Epoch 73/100\n"," - 4s - loss: 0.3030 - acc: 0.8911\n","Epoch 74/100\n"," - 4s - loss: 0.2934 - acc: 0.8923\n","Epoch 75/100\n"," - 4s - loss: 0.3094 - acc: 0.8911\n","Epoch 76/100\n"," - 4s - loss: 0.2638 - acc: 0.9097\n","Epoch 77/100\n"," - 4s - loss: 0.2670 - acc: 0.9097\n","Epoch 78/100\n"," - 4s - loss: 0.2467 - acc: 0.9183\n","Epoch 79/100\n"," - 4s - loss: 0.2757 - acc: 0.9041\n","Epoch 80/100\n"," - 4s - loss: 0.2601 - acc: 0.9084\n","Epoch 81/100\n"," - 4s - loss: 0.2580 - acc: 0.9171\n","Epoch 82/100\n"," - 4s - loss: 0.2758 - acc: 0.9004\n","Epoch 83/100\n"," - 4s - loss: 0.2524 - acc: 0.9103\n","Epoch 84/100\n"," - 4s - loss: 0.2670 - acc: 0.9103\n","Epoch 85/100\n"," - 4s - loss: 0.2773 - acc: 0.9010\n","Epoch 86/100\n"," - 4s - loss: 0.2558 - acc: 0.9109\n","Epoch 87/100\n"," - 4s - loss: 0.2462 - acc: 0.9072\n","Epoch 88/100\n"," - 4s - loss: 0.2763 - acc: 0.9072\n","Epoch 89/100\n"," - 4s - loss: 0.2778 - acc: 0.8985\n","Epoch 90/100\n"," - 4s - loss: 0.2313 - acc: 0.9233\n","Epoch 91/100\n"],"name":"stdout"},{"output_type":"stream","text":[" - 4s - loss: 0.2688 - acc: 0.9059\n","Epoch 92/100\n"," - 4s - loss: 0.2633 - acc: 0.9097\n","Epoch 93/100\n"," - 4s - loss: 0.2577 - acc: 0.9072\n","Epoch 94/100\n"," - 4s - loss: 0.2773 - acc: 0.9016\n","Epoch 95/100\n"," - 4s - loss: 0.2776 - acc: 0.8967\n","Epoch 96/100\n"," - 4s - loss: 0.2326 - acc: 0.9152\n","Epoch 97/100\n"," - 4s - loss: 0.2654 - acc: 0.9066\n","Epoch 98/100\n"," - 4s - loss: 0.2559 - acc: 0.9072\n","Epoch 99/100\n"," - 4s - loss: 0.2729 - acc: 0.9134\n","Epoch 100/100\n"," - 4s - loss: 0.2443 - acc: 0.9115\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f0ba883f550>"]},"metadata":{"tags":[]},"execution_count":28}]},{"metadata":{"id":"Wgot60j7IEwY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":51},"outputId":"2c322fdc-d285-450c-8465-99565301a1d0","executionInfo":{"status":"ok","timestamp":1523391314947,"user_tz":-330,"elapsed":1399,"user":{"displayName":"Ruthvik Reddy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"113131962877865104150"}}},"cell_type":"code","source":["model.evaluate(x=X_val_out, y=y_val, batch_size=batch_size)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["539/539 [==============================] - 1s 1ms/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.2506263633373112, 0.9202226243346432]"]},"metadata":{"tags":[]},"execution_count":29}]},{"metadata":{"id":"XSvCp1XOJmMZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":51},"outputId":"1a0b9bbf-e806-43f0-ee87-8a2fc2795d91","executionInfo":{"status":"ok","timestamp":1523391318078,"user_tz":-330,"elapsed":1525,"user":{"displayName":"Ruthvik Reddy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"113131962877865104150"}}},"cell_type":"code","source":["model.evaluate(x=X_test_out, y=y_test, batch_size=batch_size)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["539/539 [==============================] - 0s 799us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.3131854184752016, 0.8923933141085566]"]},"metadata":{"tags":[]},"execution_count":30}]}]}